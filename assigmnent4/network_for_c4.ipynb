{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć dla agenta do gry w Connect4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from imp import reload\n",
    "\n",
    "import DataLoader\n",
    "reload(DataLoader)\n",
    "\n",
    "from DataLoader import InMemDataLoader\n",
    "from DataLoader import C4DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_games = 2\n",
    "moves_observed  = 5\n",
    "dataset = C4DataSet(nr_of_games, moves_observed).create_data_set(task_nr=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3040.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4056.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4425.54it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_size, val_size, test_size = int(len(dataset)/3), int(len(dataset)/3), len(dataset)/3\n",
    "amount_of_train_batches = train_size / batch_size\n",
    "\n",
    "print(f\"train_size = {train_size}\")\n",
    "train_set = dataset[:train_size]\n",
    "val_set = dataset[train_size:train_size+val_size] \n",
    "test_set = dataset[train_size+val_size:]\n",
    "\n",
    "data_loaders = {\n",
    "    \"train\": InMemDataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "    \"valid\": InMemDataLoader(val_set, batch_size=batch_size, shuffle=False),\n",
    "    \"test\": InMemDataLoader(test_set, batch_size=batch_size, shuffle=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([0., 2., 1., 0., 2., 0., 2., 0.]), 0), (tensor([0., 1., 1., 0., 1., 0., 2., 0.]), 0), (tensor([0., 2., 1., 0., 1., 0., 2., 0.]), 0)]\n"
     ]
    }
   ],
   "source": [
    "import DataLoader\n",
    "reload(DataLoader)\n",
    "from DataLoader import C4DataSet\n",
    "\n",
    "# game = 'S233322625223356466550404A' #<-- dobry przykłąd skosu, dziury \n",
    "# game = \"S3256323326066002103304101B\"\n",
    "# game = \"S3410241441125533221302A\"\n",
    "# dataset = C4DataSet(1, \"all\")\n",
    "# samples = dataset.test_samples(game)\n",
    "# for sample in samples:\n",
    "#     print(sample)\n",
    "\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmichalfica125\u001b[0m (\u001b[33mneuralnetworks\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login() # klucz - 7242fe50822869937a282970b5385963778c7f8c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1, 2]              18\n",
      "================================================================\n",
      "Total params: 18\n",
      "Trainable params: 18\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dp=0.5):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 2) # zamiast 2 wstawić 25 \n",
    "\n",
    "        # self.bn3 = nn.BatchNorm1d(25)\n",
    "        # self.fc2 = nn.Linear(25,2)\n",
    "        # self.do = nn.Dropout(0.35)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.do(x) \n",
    "\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.do(x)\n",
    "\n",
    "        # x = nn.Softmax()(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, Out, Targets):\n",
    "      return F.cross_entropy(Out, Targets)\n",
    "\n",
    "model = Model()\n",
    "summary(model, (1,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_rate(model, data_loader, device=\"cpu\"):\n",
    "  model.eval()\n",
    "\n",
    "  num_errs, num_examples = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "\n",
    "      x, y = batch[0].to(device), batch[1].to(device)\n",
    "      out = model(x)\n",
    "\n",
    "      _, pred = out.max(dim=1)\n",
    "      num_errs += (pred != y.data).sum().item()\n",
    "      num_examples += x.size(0)\n",
    "    \n",
    "  print(f\"parametry sieci: \")\n",
    "  for _, p in model.named_parameters():\n",
    "    print(p)\n",
    "\n",
    "  print(f\"przy tych paramaetrach liczba pomyłek = {num_errs}\")\n",
    "\n",
    "  return num_errs / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_of_epochs, train_loader, opt, print_every=10, device=\"cpu\"):\n",
    "  model.train()\n",
    "\n",
    "  for data_loader in data_loaders.values():\n",
    "    if isinstance(data_loader, InMemDataLoader):\n",
    "        data_loader.to(device)\n",
    "\n",
    "  iter = 0\n",
    "  for e in range(num_of_epochs):\n",
    "    model.train()\n",
    "    print(f\"Epoch {e+1}\")\n",
    "\n",
    "    for batch in train_loader:\n",
    "      iter += 1\n",
    "      x = batch[0].to(device)\n",
    "      y = batch[1].to(device)\n",
    "      opt.zero_grad()\n",
    "      \n",
    "      out = model(x)\n",
    "      # loss = nn.CrossEntropyLoss()(out, y)\n",
    "\n",
    "      target = torch.randn(3, 2)\n",
    "      loss = nn.MSELoss()(out, target)\n",
    "      loss.backward()\n",
    "\n",
    "      print(f\"policzone gradienty: \")\n",
    "      for _, p in model.named_parameters():\n",
    "        print(p.grad)\n",
    "\n",
    "      print(f\"\\nparametry PRZED sieci: \")\n",
    "      for p in model.parameters():\n",
    "        print(p.clone())\n",
    "        print(p.requires_grad)\n",
    "\n",
    "      opt.step()\n",
    "\n",
    "      print(f\"\\nparametry PO sieci: \")\n",
    "      for p in model.parameters():\n",
    "        print(p.clone())\n",
    "        print(p.requires_grad)\n",
    "\n",
    "      _, pred = out.max(dim=1)\n",
    "      batch_err = (pred != y).sum().item() / out.size(0)\n",
    "\n",
    "      if iter % print_every == 0:\n",
    "        print(f\"iter = {iter}, batch_err = {batch_err * 100.0}\")\n",
    "        # wandb.log({\"batch_error_rate\": batch_err})\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    # val_err = compute_error_rate(model, data_loader=data_loaders[\"valid\"], device=device)\n",
    "    # print(f\"val err = {100*val_err:.2f}\")\n",
    "    # wandb.log({'val_err': val_err, 'epoch': e+1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    with torch.no_grad():\n",
    "        for name, p in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                if 'conv' in name:\n",
    "                    f_in = p.shape[1]*p.shape[2]*p.shape[3]\n",
    "                    p.normal_(0, torch.sqrt(torch.tensor(2./f_in)))\n",
    "                elif 'bn' in name:\n",
    "                    p = torch.ones_like(p)\n",
    "                elif 'fc' in name:\n",
    "                    f_in = p.shape[1]\n",
    "                    p.normal_(0, torch.sqrt(torch.tensor(2./f_in)))\n",
    "                else:\n",
    "                    raise Exception('weird weight')\n",
    "\n",
    "            elif 'bias' in name:\n",
    "                p.zero_()\n",
    "            else:\n",
    "                raise Exception('weird parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 101\n",
    "weight_decay = 0.0000001\n",
    "momentum = 0.9\n",
    "epochs = 1\n",
    "_device = \"cpu\"\n",
    "_print_every = 20\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, weight_decay = weight_decay, momentum = momentum)\n",
    "# opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "policzone gradienty: \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8410, 0.3698, 0.0000, 1.1425, 0.0000, 0.7396, 0.0000]])\n",
      "tensor([0.0000, 0.3698])\n",
      "\n",
      "parametry PRZED sieci: \n",
      "tensor([[ 2.6896e-01,  8.6646e-02,  2.5616e-01, -2.2037e-01,  2.3781e-02,\n",
      "         -7.5069e-01, -4.2765e-01,  1.0346e+00],\n",
      "        [-1.9008e-01, -1.2592e-04, -3.4191e-03,  5.7313e-01,  4.7272e-01,\n",
      "         -4.1658e-01,  1.6169e-01,  5.2713e-01]], grad_fn=<CloneBackward0>)\n",
      "True\n",
      "tensor([0., 0.], grad_fn=<CloneBackward0>)\n",
      "True\n",
      "\n",
      "parametry PO sieci: \n",
      "tensor([[ 2.6896e-01,  8.6646e-02,  2.5616e-01, -2.2037e-01,  2.3781e-02,\n",
      "         -7.5069e-01, -4.2765e-01,  1.0346e+00],\n",
      "        [-1.9008e-01, -1.2592e-04, -3.4191e-03,  5.7313e-01,  4.7272e-01,\n",
      "         -4.1658e-01,  1.6169e-01,  5.2713e-01]], grad_fn=<CloneBackward0>)\n",
      "True\n",
      "tensor([0., 0.], grad_fn=<CloneBackward0>)\n",
      "True\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UWAGI:\n",
    "# gradienty się liczą ale nie uaktualniają się wagi !!! \n",
    "# na razie nwm co z tym z robić mam inne zajęcia tez \n",
    "\n",
    "model = Model().to(\"cpu\")\n",
    "initialize_weights(model)\n",
    "\n",
    "cnt +=  1\n",
    "run_name = \"run_nr \" + str(cnt) + \" larger simple nn, 100 games\" \n",
    "# run = wandb.init(\n",
    "#     project=\"Assigmnent4 task2\",\n",
    "#     name = run_name,\n",
    "#     config={\n",
    "#         \"epochs\": epochs,\n",
    "#         \"learning_rate\": lr,\n",
    "#         \"optimizer\": \"SGD\",\n",
    "#         \"momentum\": momentum,\n",
    "#         \"weight_decay\": weight_decay,\n",
    "#         \"batch & dropout\": True,\n",
    "#     },\n",
    "# )\n",
    "# wandb.watch(model, F.cross_entropy, log=\"all\")\n",
    "\n",
    "train(num_of_epochs=epochs, train_loader=data_loaders[\"train\"], opt=opt, print_every=_print_every, device=_device)\n",
    "# test_error_rate = compute_error_rate(model, data_loaders[\"test\"], device=_device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = torch.randn(1, 8, requires_grad=True)\n",
    "target = torch.randn(1, 8)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = torch.Size([128, 8])\n",
      "out = tensor([[0.0613, 0.9387],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.2866, 0.7134],\n",
      "        [0.0061, 0.9939],\n",
      "        [0.4897, 0.5103],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1170, 0.8830],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1569, 0.8431],\n",
      "        [0.0269, 0.9731],\n",
      "        [0.5503, 0.4497],\n",
      "        [0.4624, 0.5376],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.4624, 0.5376],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0401, 0.9599],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.2356, 0.7644],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1056, 0.8944],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0779, 0.9221],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0245, 0.9755],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1717, 0.8283],\n",
      "        [0.2371, 0.7629],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0263, 0.9737],\n",
      "        [0.0401, 0.9599],\n",
      "        [0.1599, 0.8401],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1137, 0.8863],\n",
      "        [0.0063, 0.9937],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.0877, 0.9123],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.3403, 0.6597],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1569, 0.8431],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.1666, 0.8334],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.4143, 0.5857],\n",
      "        [0.6845, 0.3155],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0063, 0.9937],\n",
      "        [0.3067, 0.6933],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.0409, 0.9591],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.7024, 0.2976],\n",
      "        [0.0569, 0.9431],\n",
      "        [0.4478, 0.5522],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0607, 0.9393],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1627, 0.8373],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0316, 0.9684],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1637, 0.8363],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2005, 0.7995],\n",
      "        [0.1512, 0.8488],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.1891, 0.8109],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0540, 0.9460],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.0616, 0.9384],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3278, 0.6722],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.0805, 0.9195],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0616, 0.9384],\n",
      "        [0.4143, 0.5857],\n",
      "        [0.0631, 0.9369],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2314, 0.7686],\n",
      "        [0.2188, 0.7812],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.4115, 0.5885],\n",
      "        [0.0794, 0.9206],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3417, 0.6583]])\n",
      "pred =tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "0.421875\n",
      "x = torch.Size([128, 8])\n",
      "out = tensor([[0.0858, 0.9142],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3561, 0.6439],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3126, 0.6874],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0418, 0.9582],\n",
      "        [0.4624, 0.5376],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0431, 0.9569],\n",
      "        [0.3826, 0.6174],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.2327, 0.7673],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.5460, 0.4540],\n",
      "        [0.4276, 0.5724],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3826, 0.6174],\n",
      "        [0.1569, 0.8431],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3764, 0.6236],\n",
      "        [0.1048, 0.8952],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.4766, 0.5234],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2424, 0.7576],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0409, 0.9591],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.2921, 0.7079],\n",
      "        [0.1540, 0.8460],\n",
      "        [0.0711, 0.9289],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.2117, 0.7883],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.0791, 0.9209],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.8715, 0.1285],\n",
      "        [0.0263, 0.9737],\n",
      "        [0.1003, 0.8997],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2895, 0.7105],\n",
      "        [0.4599, 0.5401],\n",
      "        [0.0597, 0.9403],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.6280, 0.3720],\n",
      "        [0.3826, 0.6174],\n",
      "        [0.4115, 0.5885],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2893, 0.7107],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1056, 0.8944],\n",
      "        [0.1877, 0.8123],\n",
      "        [0.1717, 0.8283],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.2673, 0.7327],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0157, 0.9843],\n",
      "        [0.0514, 0.9486],\n",
      "        [0.6280, 0.3720],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1901, 0.8099],\n",
      "        [0.0174, 0.9826],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.0448, 0.9552],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569]])\n",
      "pred =tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "0.4921875\n",
      "x = torch.Size([128, 8])\n",
      "out = tensor([[0.3931, 0.6069],\n",
      "        [0.4473, 0.5527],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.0514, 0.9486],\n",
      "        [0.2327, 0.7673],\n",
      "        [0.0297, 0.9703],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1717, 0.8283],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.7024, 0.2976],\n",
      "        [0.2417, 0.7583],\n",
      "        [0.4099, 0.5901],\n",
      "        [0.2371, 0.7629],\n",
      "        [0.1226, 0.8774],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1717, 0.8283],\n",
      "        [0.6485, 0.3515],\n",
      "        [0.4301, 0.5699],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.0627, 0.9373],\n",
      "        [0.3031, 0.6969],\n",
      "        [0.1198, 0.8802],\n",
      "        [0.5785, 0.4215],\n",
      "        [0.5503, 0.4497],\n",
      "        [0.1147, 0.8853],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.1045, 0.8955],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1599, 0.8401],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2701, 0.7299],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.1955, 0.8045],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.1056, 0.8944],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2888, 0.7112],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.0174, 0.9826],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.0138, 0.9862],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1317, 0.8683],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0107, 0.9893],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.5785, 0.4215],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.1358, 0.8642],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0348, 0.9652],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.2417, 0.7583],\n",
      "        [0.0157, 0.9843],\n",
      "        [0.1056, 0.8944],\n",
      "        [0.0486, 0.9514],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0757, 0.9243],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1003, 0.8997],\n",
      "        [0.0697, 0.9303],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.0431, 0.9569],\n",
      "        [0.2314, 0.7686],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.6485, 0.3515],\n",
      "        [0.2117, 0.7883],\n",
      "        [0.3039, 0.6961],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.5503, 0.4497],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1877, 0.8123],\n",
      "        [0.1335, 0.8665],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1056, 0.8944],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.6845, 0.3155],\n",
      "        [0.0275, 0.9725],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0607, 0.9393],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.1748, 0.8252],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.5503, 0.4497],\n",
      "        [0.4115, 0.5885],\n",
      "        [0.0613, 0.9387],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.2764, 0.7236],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0996, 0.9004],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1241, 0.8759],\n",
      "        [0.5785, 0.4215],\n",
      "        [0.2143, 0.7857]])\n",
      "pred =tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1])\n",
      "0.5234375\n",
      "x = torch.Size([128, 8])\n",
      "out = tensor([[0.3683, 0.6317],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0275, 0.9725],\n",
      "        [0.3418, 0.6582],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.1048, 0.8952],\n",
      "        [0.1877, 0.8123],\n",
      "        [0.0174, 0.9826],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.0697, 0.9303],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0448, 0.9552],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0786, 0.9214],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0597, 0.9403],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1380, 0.8620],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.1569, 0.8431],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.4599, 0.5401],\n",
      "        [0.6914, 0.3086],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.6633, 0.3367],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1877, 0.8123],\n",
      "        [0.6845, 0.3155],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.4635, 0.5365],\n",
      "        [0.3926, 0.6074],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1604, 0.8396],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.1304, 0.8696],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2638, 0.7362],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.6485, 0.3515],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0840, 0.9160],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0295, 0.9705],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.0138, 0.9862],\n",
      "        [0.2921, 0.7079],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.4115, 0.5885],\n",
      "        [0.1599, 0.8401],\n",
      "        [0.5087, 0.4913],\n",
      "        [0.0962, 0.9038],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.1446, 0.8554],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.2117, 0.7883],\n",
      "        [0.0269, 0.9731],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.4006, 0.5994],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.6845, 0.3155],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1287, 0.8713],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0616, 0.9384],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.1877, 0.8123],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.3964, 0.6036],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.1056, 0.8944],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.3051, 0.6949],\n",
      "        [0.4478, 0.5522],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.5336, 0.4664],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1056, 0.8944]])\n",
      "pred =tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1])\n",
      "0.6171875\n",
      "x = torch.Size([128, 8])\n",
      "out = tensor([[0.2143, 0.7857],\n",
      "        [0.1003, 0.8997],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1886, 0.8114],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0107, 0.9893],\n",
      "        [0.1604, 0.8396],\n",
      "        [0.0508, 0.9492],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0490, 0.9510],\n",
      "        [0.0401, 0.9599],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2399, 0.7601],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.0805, 0.9195],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.2123, 0.7877],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.4115, 0.5885],\n",
      "        [0.0597, 0.9403],\n",
      "        [0.5785, 0.4215],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.3051, 0.6949],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.3826, 0.6174],\n",
      "        [0.2399, 0.7601],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.5785, 0.4215],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.0138, 0.9862],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.6485, 0.3515],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.3683, 0.6317],\n",
      "        [0.4236, 0.5764],\n",
      "        [0.4473, 0.5527],\n",
      "        [0.0741, 0.9259],\n",
      "        [0.3502, 0.6498],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0238, 0.9762],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2417, 0.7583],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0597, 0.9403],\n",
      "        [0.0245, 0.9755],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.0238, 0.9762],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.2371, 0.7629],\n",
      "        [0.3926, 0.6074],\n",
      "        [0.1901, 0.8099],\n",
      "        [0.3403, 0.6597],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2117, 0.7883],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0263, 0.9737],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1003, 0.8997],\n",
      "        [0.2127, 0.7873],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1335, 0.8665],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.2895, 0.7105],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3865, 0.6135],\n",
      "        [0.1056, 0.8944],\n",
      "        [0.1232, 0.8768],\n",
      "        [0.0100, 0.9900],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2877, 0.7123],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1294, 0.8706],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0348, 0.9652],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0697, 0.9303],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.0547, 0.9453],\n",
      "        [0.5370, 0.4630],\n",
      "        [0.3358, 0.6642],\n",
      "        [0.0063, 0.9937],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1599, 0.8401],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.5324, 0.4676],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0329, 0.9671],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.3431, 0.6569]])\n",
      "pred =tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1])\n",
      "0.578125\n",
      "x = torch.Size([128, 8])\n",
      "out = tensor([[0.1045, 0.8955],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.1901, 0.8099],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0514, 0.9486],\n",
      "        [0.5503, 0.4497],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.2786, 0.7214],\n",
      "        [0.3039, 0.6961],\n",
      "        [0.1711, 0.8289],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2638, 0.7362],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.4599, 0.5401],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.1446, 0.8554],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0263, 0.9737],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.1891, 0.8109],\n",
      "        [0.3926, 0.6074],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.1011, 0.8989],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1241, 0.8759],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1003, 0.8997],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.3683, 0.6317],\n",
      "        [0.0977, 0.9023],\n",
      "        [0.0402, 0.9598],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.4599, 0.5401],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0263, 0.9737],\n",
      "        [0.3683, 0.6317],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.1599, 0.8401],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.0027, 0.9973],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.1045, 0.8955],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.3865, 0.6135],\n",
      "        [0.0138, 0.9862],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0329, 0.9671],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0514, 0.9486],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2005, 0.7995],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.1717, 0.8283],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1091, 0.8909],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1540, 0.8460],\n",
      "        [0.1028, 0.8972],\n",
      "        [0.0977, 0.9023],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.2417, 0.7583],\n",
      "        [0.3502, 0.6498],\n",
      "        [0.1569, 0.8431],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.2327, 0.7673],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1599, 0.8401],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0448, 0.9552],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.4624, 0.5376],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.1540, 0.8460],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.2295, 0.7705],\n",
      "        [0.2417, 0.7583],\n",
      "        [0.0741, 0.9259],\n",
      "        [0.0523, 0.9477],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0514, 0.9486],\n",
      "        [0.0238, 0.9762],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0488, 0.9512],\n",
      "        [0.0631, 0.9369],\n",
      "        [0.2510, 0.7490]])\n",
      "pred =tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "0.5390625\n",
      "x = torch.Size([128, 8])\n",
      "out = tensor([[0.3683, 0.6317],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1294, 0.8706],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.1717, 0.8283],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.7024, 0.2976],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.6485, 0.3515],\n",
      "        [0.0329, 0.9671],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1011, 0.8989],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.2921, 0.7079],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2399, 0.7601],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.0631, 0.9369],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.6280, 0.3720],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1335, 0.8665],\n",
      "        [0.0564, 0.9436],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0295, 0.9705],\n",
      "        [0.3920, 0.6080],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0138, 0.9862],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3051, 0.6949],\n",
      "        [0.2417, 0.7583],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.1049, 0.8951],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.6685, 0.3315],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0438, 0.9562],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.5460, 0.4540],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.3051, 0.6949],\n",
      "        [0.1627, 0.8373],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.2137, 0.7863],\n",
      "        [0.1864, 0.8136],\n",
      "        [0.0431, 0.9569],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.2582, 0.7418],\n",
      "        [0.0165, 0.9835],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.1569, 0.8431],\n",
      "        [0.0138, 0.9862],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.5668, 0.4332],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.3600, 0.6400],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0438, 0.9562],\n",
      "        [0.1287, 0.8713],\n",
      "        [0.3403, 0.6597],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0269, 0.9731],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.6454, 0.3546],\n",
      "        [0.2638, 0.7362],\n",
      "        [0.0348, 0.9652],\n",
      "        [0.2408, 0.7592],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2888, 0.7112],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.5503, 0.4497],\n",
      "        [0.1550, 0.8450],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3926, 0.6074],\n",
      "        [0.6845, 0.3155],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.2895, 0.7105],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1543, 0.8457],\n",
      "        [0.2408, 0.7592]])\n",
      "pred =tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1])\n",
      "0.484375\n",
      "x = torch.Size([128, 8])\n",
      "out = tensor([[0.1439, 0.8561],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.0616, 0.9384],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.4902, 0.5098],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0564, 0.9436],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0697, 0.9303],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.0962, 0.9038],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.0326, 0.9674],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.6633, 0.3367],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1965, 0.8035],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1048, 0.8952],\n",
      "        [0.0269, 0.9731],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.0401, 0.9599],\n",
      "        [0.1011, 0.8989],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0104, 0.9896],\n",
      "        [0.0791, 0.9209],\n",
      "        [0.2976, 0.7024],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1335, 0.8665],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1182, 0.8818],\n",
      "        [0.3600, 0.6400],\n",
      "        [0.1569, 0.8431],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3502, 0.6498],\n",
      "        [0.1271, 0.8729],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0409, 0.9591],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.5668, 0.4332],\n",
      "        [0.2701, 0.7299],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.1425, 0.8575],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.1603, 0.8397],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.1877, 0.8123],\n",
      "        [0.1531, 0.8469],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2883, 0.7117],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0269, 0.9731],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1049, 0.8951],\n",
      "        [0.0238, 0.9762],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1569, 0.8431],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3826, 0.6174],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2275, 0.7725],\n",
      "        [0.0474, 0.9526],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1287, 0.8713],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3051, 0.6949],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0713, 0.9287],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.0263, 0.9737],\n",
      "        [0.0744, 0.9256],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.0409, 0.9591],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2895, 0.7105],\n",
      "        [0.4143, 0.5857],\n",
      "        [0.1011, 0.8989],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2417, 0.7583],\n",
      "        [0.0560, 0.9440],\n",
      "        [0.2510, 0.7490],\n",
      "        [0.4624, 0.5376],\n",
      "        [0.4473, 0.5527],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.7024, 0.2976],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.0269, 0.9731],\n",
      "        [0.0972, 0.9028],\n",
      "        [0.2417, 0.7583],\n",
      "        [0.5460, 0.4540],\n",
      "        [0.2417, 0.7583]])\n",
      "pred =tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1])\n",
      "0.5078125\n",
      "x = torch.Size([54, 8])\n",
      "out = tensor([[0.1484, 0.8516],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.1569, 0.8431],\n",
      "        [0.0676, 0.9324],\n",
      "        [0.4902, 0.5098],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.0827, 0.9173],\n",
      "        [0.2371, 0.7629],\n",
      "        [0.4239, 0.5761],\n",
      "        [0.4624, 0.5376],\n",
      "        [0.3051, 0.6949],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.1198, 0.8802],\n",
      "        [0.1003, 0.8997],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.1535, 0.8465],\n",
      "        [0.2490, 0.7510],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.3826, 0.6174],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.3683, 0.6317],\n",
      "        [0.6283, 0.3717],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.0401, 0.9599],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.3431, 0.6569],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2921, 0.7079],\n",
      "        [0.1189, 0.8811],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.0858, 0.9142],\n",
      "        [0.2582, 0.7418],\n",
      "        [0.1011, 0.8989],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2012, 0.7988],\n",
      "        [0.7665, 0.2335],\n",
      "        [0.4286, 0.5714],\n",
      "        [0.4949, 0.5051],\n",
      "        [0.3309, 0.6691],\n",
      "        [0.2794, 0.7206],\n",
      "        [0.3417, 0.6583],\n",
      "        [0.3039, 0.6961],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.1002, 0.8998]])\n",
      "pred =tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1])\n",
      "0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in data_loaders['train']:\n",
    "        x = x.to(\"cpu\")\n",
    "        print(f\"x = {x.shape}\")\n",
    "        # print(f\"y = {y}\")\n",
    "        out = model(x)\n",
    "        print(f\"out = {out}\")\n",
    "        _, pred = out.max(dim=1)\n",
    "        print(f\"pred ={pred}\")\n",
    "\n",
    "        batch_err = (pred != y).sum().item() / out.size(0)\n",
    "\n",
    "        print(batch_err)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
